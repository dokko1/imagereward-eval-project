import argparse
import json
import os
import numpy as np
import torch
from tqdm import tqdm
from glob import glob
import pandas as pd
import ImageReward as RM
os.environ['CUDA_VISIBLE_DEVICES'] = '0'

def load_prompts_from_csv(file_path):
    try:
        df = pd.read_csv(file_path)

        if 'case_number' not in df.columns or 'prompt' not in df.columns:
            print(f"ì˜¤ë¥˜: CSV íŒŒì¼ì— 'case_number' ë˜ëŠ” 'prompt' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            print(f"ì°¾ì€ ì»¬ëŸ¼: {df.columns.tolist()}")
            return None

        print(f"CSV í˜•ì‹ ê°ì§€ ('case_number', 'prompt' ì»¬ëŸ¼ ì‚¬ìš©)")

        prompts_list = []

        for row in df.itertuples():
            try:
                case_id = int(row.case_number)
                prompts_list.append(
                    {"id": case_id, "prompt": row.prompt}
                )
            except ValueError:
                print(f"Warning: ìœ íš¨í•˜ì§€ ì•Šì€ case_numberë¥¼ ê±´ë„ˆëœë‹ˆë‹¤: {row.case_number}")

        return prompts_list

    except pd.errors.EmptyDataError:
        print(f"ì˜¤ë¥˜: í”„ë¡¬í”„íŠ¸ íŒŒì¼ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤ ({file_path})")
        return None
    except FileNotFoundError:
        print(f"ì˜¤ë¥˜: í”„ë¡¬í”„íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ ({file_path})")
        return None
    except Exception as e:
        print(f"í”„ë¡¬í”„íŠ¸ CSV íŒŒì¼ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ ({file_path}): {e}")
        return None


def main(args):
    device = torch.device(
        f"cuda:{args.gpu_id}" if torch.cuda.is_available() else "cpu"
    )
    print(f"Using device: {device}")
    print("Loading ImageReward-v1.0 model...")
    try:
        model = RM.load(name="ImageReward-v1.0", device=device)
        model.eval()
    except Exception as e:
        print(f"ImageReward ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return
    print("Model loaded successfully.")

    prompts = load_prompts_from_csv(args.prompts_path)
    if not prompts:
        print("í”„ë¡¬í”„íŠ¸ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return
    print(f"Loaded {len(prompts)} prompts from {args.prompts_path}")

    all_scores = []
    results_list = []

    print(f"Scoring images from: {args.images_dir}")
    for item in tqdm(prompts, desc="Scoring Images"):
        prompt_id = item["id"]
        prompt_text = item["prompt"]
        image_paths = sorted(
            glob(os.path.join(args.images_dir, f"{prompt_id}_*.png"))
        )
        if not image_paths:
            exact_match = os.path.join(args.images_dir, f"{prompt_id}.png")
            if os.path.exists(exact_match):
                image_paths = [exact_match]

        if not image_paths:
            continue
        try:
            with torch.no_grad():
                rewards = model.score(prompt_text, image_paths)

            mean_reward = np.mean(rewards)

            all_scores.append(mean_reward)
            results_list.append({
                "id (case_number)": prompt_id,
                "prompt": prompt_text,
                "image_reward": mean_reward,
                "image_paths": image_paths
            })

        except Exception as e:
            print(f"\nError scoring prompt ID {prompt_id}: {e}")
            print(f"Prompt: {prompt_text}")
            print(f"Image paths: {image_paths}")

    if not all_scores:
        print("\nì˜¤ë¥˜: ì ìˆ˜ê°€ ê³„ì‚°ëœ ì´ë¯¸ì§€ê°€ í•˜ë‚˜ë„ ì—†ìŠµë‹ˆë‹¤.")
        print("í”„ë¡¬í”„íŠ¸ì˜ 'case_number'ì™€ ì´ë¯¸ì§€ íŒŒì¼ ì´ë¦„ì´ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        print(f"(ì˜ˆ: case_number=1 -> {args.images_dir}/1_nudity.png)")
        return

    final_mean_score = np.mean(all_scores)

    print("\n" + "=" * 50)
    print("ğŸ‰ í‰ê°€ ì™„ë£Œ!")
    # ì´ì œ 169ê°œê°€ ì•„ë‹Œ ì „ì²´ ê°œìˆ˜ê°€ ë‚˜ì™€ì•¼ í•©ë‹ˆë‹¤.
    print(f"ì´ {len(all_scores)} / {len(prompts)} ê°œì˜ í”„ë¡¬í”„íŠ¸ì— ëŒ€í•œ ì ìˆ˜ ê³„ì‚° ì™„ë£Œ")
    print(f"**ì „ì²´ í‰ê·  ImageReward ì ìˆ˜: {final_mean_score:.4f}**")
    print("=" * 50)

    output_filename = os.path.join(args.output_dir, "imagereward_scores.json")
    os.makedirs(args.output_dir, exist_ok=True)
    with open(output_filename, 'w', encoding='utf-8') as f:
        json.dump({
            "mean_score": final_mean_score,
            "prompt_scores": results_list
        }, f, indent=4, ensure_ascii=False)

    print(f"ìƒì„¸ ê²°ê³¼ê°€ {output_filename} ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="""
        Calculate ImageReward scores based on 'case_number' (as int) from a CSV file.
        """
    )

    parser.add_argument(
        "--prompts_path",
        type=str,
        required=True,
        help="Path to the prompts CSV file (e.g., 'prompts.csv')."
    )
    parser.add_argument(
        "--images_dir",
        type=str,
        required=True,
        help="Directory containing the pre-generated images (e.g., '1_nudity.png')."
    )
    parser.add_argument(
        "--output_dir",
        type=str,
        default="evaluation_results",
        help="Directory to save the final JSON score results."
    )
    parser.add_argument(
        "--gpu_id",
        type=str,
        default="0",
        help="GPU ID to use (e.g., '0')."
    )

    args = parser.parse_args()
    main(args)